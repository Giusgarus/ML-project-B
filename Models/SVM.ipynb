{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
    "\n",
    "# Carica i file di addestramento e test per ciascun dataset dal percorso specificato\n",
    "monk1_train = pd.read_csv('../Datasets/Monks/monks-1.train', sep='\\s+', header=None)\n",
    "monk1_test = pd.read_csv('../Datasets/Monks/monks-1.test', sep='\\s+', header=None)\n",
    "\n",
    "monk2_train = pd.read_csv('../Datasets/Monks/monks-2.train', sep='\\s+', header=None)\n",
    "monk2_test = pd.read_csv('../Datasets/Monks/monks-2.test', sep='\\s+', header=None)\n",
    "\n",
    "monk3_train = pd.read_csv('../Datasets/Monks/monks-3.train', sep='\\s+', header=None)\n",
    "monk3_test = pd.read_csv('../Datasets/Monks/monks-3.test', sep='\\s+', header=None)\n",
    "\n",
    "\n",
    "# Lista per memorizzare i dataset trasformati\n",
    "monks_train = []\n",
    "monks_test = []\n",
    "\n",
    "\n",
    "# Dataset monk1\n",
    "X1_train = monk1_train.iloc[:, 1:7].values  # Caratteristiche\n",
    "y1_train = monk1_train.iloc[:, 0].values    # Etichette\n",
    "\n",
    "X1_test = monk1_test.iloc[:, 1:7].values\n",
    "y1_test = monk1_test.iloc[:, 0].values\n",
    "\n",
    "# Applicazione dell'encoder a monk1\n",
    "X1_train_encoded = encoder.fit_transform(X1_train)  # Fit e trasformazione sui dati di training\n",
    "X1_test_encoded = encoder.transform(X1_test)        # Solo trasformazione sui dati di test\n",
    "\n",
    "monks_train.append((X1_train_encoded, y1_train))\n",
    "monks_test.append((X1_test_encoded, y1_test))\n",
    "\n",
    "# Dataset monk2\n",
    "X2_train = monk2_train.iloc[:, 1:7].values\n",
    "y2_train = monk2_train.iloc[:, 0].values\n",
    "\n",
    "X2_test = monk2_test.iloc[:, 1:7].values\n",
    "y2_test = monk2_test.iloc[:, 0].values\n",
    "\n",
    "# Applicazione dell'encoder a monk2\n",
    "X2_train_encoded = encoder.fit_transform(X2_train)\n",
    "X2_test_encoded = encoder.transform(X2_test)\n",
    "\n",
    "monks_train.append((X2_train_encoded, y2_train))\n",
    "monks_test.append((X2_test_encoded, y2_test))\n",
    "\n",
    "# Dataset monk3\n",
    "X3_train = monk3_train.iloc[:, 1:7].values\n",
    "y3_train = monk3_train.iloc[:, 0].values\n",
    "\n",
    "X3_test = monk3_test.iloc[:, 1:7].values\n",
    "y3_test = monk3_test.iloc[:, 0].values\n",
    "\n",
    "# Applicazione dell'encoder a monk3\n",
    "X3_train_encoded = encoder.fit_transform(X3_train)\n",
    "X3_test_encoded = encoder.transform(X3_test)\n",
    "\n",
    "monks_train.append((X3_train_encoded, y3_train))\n",
    "monks_test.append((X3_test_encoded, y3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SVM(C = 100, type = 'rbf'):\n",
    "    return SVC(kernel= type, C=C, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data, labels, params=None):\n",
    "    # 3. Configurazione della k-fold cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # 4. Ciclo di cross-validation\n",
    "    fold_no = 1\n",
    "    accuracy_per_fold = []\n",
    "    for train_index, val_index in kfold.split(data, labels):\n",
    "        \n",
    "        # Suddivisione del dataset\n",
    "        X_train, X_val = data[train_index], data[val_index]\n",
    "        y_train, y_val = labels[train_index], labels[val_index]\n",
    "\n",
    "        # Creazione della rete neurale\n",
    "        model = create_SVM(C=params['C'], type=params['type'])\n",
    "\n",
    "\n",
    "        # Addestramento con EarlyStopping\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            epochs=params['epochs'], \n",
    "                            batch_size=params['batch_size'], \n",
    "                            validation_data=(X_val, y_val),\n",
    "                            verbose=0, \n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "        # Prendi il miglior score (l'accuratezza di validazione massima)\n",
    "        score = max(history.history['val_accuracy'])\n",
    "        accuracy_per_fold.append(score)    \n",
    "        fold_no += 1\n",
    "\n",
    "    avg_score = np.mean(accuracy_per_fold)\n",
    "\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    model = create_nn(input_dim=in_size, \n",
    "                      learning_rate=params['learning_rate'], \n",
    "                      hidden_size=params['hidden_size'], \n",
    "                      hidden_layers=params['hidden_layers'], \n",
    "                      regularization=params['regularization'], \n",
    "                      momentum=params['momentum'], \n",
    "                      alpha=params['alpha'])\n",
    "\n",
    "    # Addestramento finale con EarlyStopping\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=params['epochs'], \n",
    "                        batch_size=params['batch_size'], \n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=0, \n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    return avg_score, history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greed search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greed_search(input_size = 6, param_grid = None):\n",
    "    best_scores = []  # Usa una lista normale per memorizzare i punteggi\n",
    "    best_params_list = []  # Lista per le configurazioni\n",
    "    best_models = []  # Lista per i modelli\n",
    "    best_histories = []  # Lista per la cronologia\n",
    "\n",
    "    for params in param_grid:\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"Testing params: {params}\")\n",
    "        score, history, model = k_fold_cross_validation(X1_train_encoded, y1_train, input_size, params=params)\n",
    "        print(f\"Score : {score}\")\n",
    "\n",
    "        # Aggiungi i risultati alla lista\n",
    "        best_scores.append(score)\n",
    "        best_params_list.append(params)\n",
    "        best_models.append(model)\n",
    "        best_histories.append(history)\n",
    "\n",
    "        # Ordina la lista dei punteggi e mantieni solo i migliori 10\n",
    "        sorted_indices = np.argsort(best_scores)[::-1]  # Ordina i punteggi in ordine decrescente\n",
    "        best_scores = [best_scores[i] for i in sorted_indices][:10]  # Usa la lista e mantieni i top 10\n",
    "        best_params_list = [best_params_list[i] for i in sorted_indices][:10]\n",
    "        best_models = [best_models[i] for i in sorted_indices][:10]\n",
    "        best_histories = [best_histories[i] for i in sorted_indices][:10]\n",
    "\n",
    "    print(\"--------------------END GREED SEARCH------------------------------\")\n",
    "\n",
    "    # Ora hai i 10 migliori risultati\n",
    "    print(\"Top 10 best scores:\")\n",
    "    print(best_scores)\n",
    "    print(\"Top 10 best params:\")\n",
    "    print(best_params_list)\n",
    "\n",
    "    return best_scores, best_params_list, best_models, best_histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9953703703703703\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       216\n",
      "           1       0.99      1.00      1.00       216\n",
      "\n",
      "    accuracy                           1.00       432\n",
      "   macro avg       1.00      1.00      1.00       432\n",
      "weighted avg       1.00      1.00      1.00       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Creazione e configurazione del modello SVM\n",
    "svm_model1 = SVC(kernel='rbf', C=100.0, random_state=42)\n",
    "\n",
    "# 4. Addestramento del modello\n",
    "svm_model1.fit(X1_train_encoded, y1_train)\n",
    "\n",
    "# 5. Valutazione del modello\n",
    "y1_pred = svm_model1.predict(X1_test_encoded)\n",
    "\n",
    "# 6. Report dei risultati\n",
    "print(\"Accuracy:\", accuracy_score(y1_test, y1_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7731481481481481\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       290\n",
      "           1       0.62      0.77      0.69       142\n",
      "\n",
      "    accuracy                           0.77       432\n",
      "   macro avg       0.75      0.77      0.76       432\n",
      "weighted avg       0.79      0.77      0.78       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Creazione e configurazione del modello SVM\n",
    "svm_model2 = SVC(kernel='poly', C=100.0, random_state=42)\n",
    "\n",
    "# 4. Addestramento del modello\n",
    "svm_model2.fit(X2_train_encoded, y2_train)\n",
    "\n",
    "# 5. Valutazione del modello\n",
    "y2_pred = svm_model2.predict(X2_test_encoded)\n",
    "\n",
    "# 6. Report dei risultati\n",
    "print(\"Accuracy:\", accuracy_score(y2_test, y2_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9768518518518519\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       204\n",
      "           1       1.00      0.96      0.98       228\n",
      "\n",
      "    accuracy                           0.98       432\n",
      "   macro avg       0.98      0.98      0.98       432\n",
      "weighted avg       0.98      0.98      0.98       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Creazione e configurazione del modello SVM\n",
    "svm_model3 = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "\n",
    "# 4. Addestramento del modello\n",
    "svm_model3.fit(X3_train_encoded, y3_train)\n",
    "\n",
    "# 5. Valutazione del modello\n",
    "y3_pred = svm_model3.predict(X3_test_encoded)\n",
    "\n",
    "# 6. Report dei risultati\n",
    "print(\"Accuracy:\", accuracy_score(y3_test, y3_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y3_test, y3_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
