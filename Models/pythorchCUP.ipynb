{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN implemetation with Pythorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class compatible with PyTorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, Y):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with input data (X) and labels (Y).\n",
    "\n",
    "        Args:\n",
    "            X (array-like): Input data, e.g., features or independent variables.\n",
    "            Y (array-like): Labels or targets associated with the input data.\n",
    "        \"\"\"\n",
    "        # Converts the input data and labels to PyTorch tensors with dtype float32\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The length of the dataset (number of samples).\n",
    "        \"\"\"\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a specific sample from the dataset based on an index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the desired sample.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the input data and the corresponding label (X[idx], Y[idx]).\n",
    "        \"\"\"\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait before stopping training if no improvement. Default: 5.\n",
    "            delta (float): Minimum improvement required to consider progress. Default: 0.\n",
    "            path (str): Path to save the best model. Default: 'checkpoint.pt'.\n",
    "            verbose (bool): Print messages when the model improves. Default: False.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping: No improvement for {self.counter} epochs\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Save the model when validation loss improves.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss and accuracy from a model's history.\n",
    "\n",
    "    Parameters:\n",
    "    - history: History object returned by model.fit().\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract data from the history object\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_mee = history['train_mee']\n",
    "    val_mee = history['val_mee']\n",
    "    \n",
    "    # Determine the number of epochs\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # Plot the training and validation loss\n",
    "    plt.figure(figsize=(12, 5))  # Create a figure with a specific size\n",
    "    plt.subplot(1, 2, 1)  # Create a subplot (1 row, 2 columns, 1st plot)\n",
    "    plt.plot(epochs, train_loss, 'b-o', label='Training Loss')  # Plot training loss\n",
    "    if val_loss:\n",
    "        plt.plot(epochs, val_loss, 'r-o', label='Validation Loss')  # Plot validation loss if available\n",
    "    plt.title('Training and Validation Loss')  # Set the title of the plot\n",
    "    plt.xlabel('Epochs')  # Set the x-axis label\n",
    "    plt.ylabel('Loss')  # Set the y-axis label\n",
    "    plt.legend()  # Add a legend to the plot\n",
    "    plt.grid(True)  # Add a grid to the plot\n",
    "    \n",
    "    # Plot the training and validation MEE\n",
    "    plt.subplot(1, 2, 2)  # Create a subplot (1 row, 2 columns, 2nd plot)\n",
    "    if train_mee:\n",
    "        plt.plot(epochs, train_mee, 'b-o', label='Training MEE')  # Plot training MEE if available\n",
    "    if val_mee:\n",
    "        plt.plot(epochs, val_mee, 'r-o', label='Validation MEE')  # Plot validation MEE if available\n",
    "    plt.title('Training and Validation MEE')  # Set the title of the plot\n",
    "    plt.xlabel('Epochs')  # Set the x-axis label\n",
    "    plt.ylabel('MEE')  # Set the y-axis label\n",
    "    plt.legend()  # Add a legend to the plot\n",
    "    plt.grid(True)  # Add a grid to the plot\n",
    "    \n",
    "    # Display the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss and accuracy from a model's history.\n",
    "\n",
    "    Parameters:\n",
    "    - history: History object returned by model.fit().\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract data from the history object\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_mee = history['train_mee']\n",
    "    val_mee = history['val_mee']\n",
    "    test_loss = history['test_loss']\n",
    "    test_mee = history['test_mee']\n",
    "    \n",
    "    # Determine the number of epochs\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # Plot the training and validation loss and MEE\n",
    "    plt.figure(figsize=(12, 5))  # Create a figure with a specific size\n",
    "    plt.subplot(1, 2, 1)  # Create a subplot (1 row, 2 columns, 1st plot)\n",
    "    plt.plot(epochs, train_loss, 'b-o', label='Training Loss')  # Plot training loss\n",
    "    if val_loss:\n",
    "        plt.plot(epochs, val_loss, 'r-o', label='Validation Loss')  # Plot validation loss if available\n",
    "    if test_loss:\n",
    "        plt.plot(epochs, test_loss, 'g-o', label='Test Loss')  # Plot test loss if available\n",
    "    plt.title('Training and Validation Loss')  # Set the title of the plot\n",
    "    plt.xlabel('Epochs')  # Set the x-axis label\n",
    "    plt.ylabel('Loss')  # Set the y-axis label\n",
    "    plt.legend()  # Add a legend to the plot\n",
    "    plt.grid(True)  # Add a grid to the plot\n",
    "    \n",
    "    # Plot the training and validation MEE\n",
    "    plt.subplot(1, 2, 2)  # Create a subplot (1 row, 2 columns, 2nd plot)\n",
    "    if train_mee:\n",
    "        plt.plot(epochs, train_mee, 'b-o', label='Training MEE')  # Plot training MEE if available\n",
    "    if val_mee:\n",
    "        plt.plot(epochs, val_mee, 'r-o', label='Validation MEE')  # Plot validation MEE if available\n",
    "    if test_mee:\n",
    "        plt.plot(epochs, test_mee, 'g-o', label='Test MEE')  # Plot test MEE if available\n",
    "    plt.title('Training and Validation MEE')  # Set the title of the plot\n",
    "    plt.xlabel('Epochs')  # Set the x-axis label\n",
    "    plt.ylabel('MEE')  # Set the y-axis label\n",
    "    plt.legend()  # Add a legend to the plot\n",
    "    plt.grid(True)  # Add a grid to the plot\n",
    "    \n",
    "    # Display the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hyperparameter_combinations(param_ranges):\n",
    "    \"\"\"\n",
    "    Generate all combinations of hyperparameters based on specified ranges and steps.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    - param_ranges: Dictionary with hyperparameter names as keys.\n",
    "                         Each value is a tuple (start, stop, step).\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    - List of dictionaries with all possible combinations.\n",
    "    \"\"\"\n",
    "    # Create a dictionary where each key is a hyperparameter name and each value is an array of possible values\n",
    "    param_values = {\n",
    "        key: np.arange(start, stop + step, step)  # Generate values from start to stop with the given step\n",
    "        for key, (start, stop, step) in param_ranges.items()\n",
    "    }\n",
    "    \n",
    "    # Generate all possible combinations of hyperparameter values\n",
    "    param_combinations = list(itertools.product(*param_values.values()))\n",
    "    \n",
    "    # Convert each combination from a tuple to a dictionary\n",
    "    return [\n",
    "        dict(zip(param_values.keys(), combination))  # Create a dictionary for each combination\n",
    "        for combination in param_combinations\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation, train and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    \"\"\"\n",
    "    A class to define a custom neural network using PyTorch.\n",
    "    Supports configurable hidden layers and activation functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, hidden_layers, alpha, activ_type='tanh'):\n",
    "        \"\"\"\n",
    "        Initializes the neural network with the specified parameters.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of neurons in the input layer.\n",
    "            hidden_size (int): Number of neurons in each hidden layer.\n",
    "            output_size (int): Number of neurons in the output layer.\n",
    "            hidden_layers (int): Total number of hidden layers.\n",
    "            alpha (float): Parameter for the LeakyReLU activation function (if selected).\n",
    "            activ_type (str, optional): Type of activation function ('tanh', 'leaky_relu', 'relu'). Default is 'tanh'.\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        # First fully connected layer (input -> hidden layer)\n",
    "        self.fc_input = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Hidden fully connected layers\n",
    "        self.fc_hidden = [None] * (hidden_layers - 1)\n",
    "        for i in range(hidden_layers - 1):\n",
    "            self.fc_hidden[i] = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # Output fully connected layer (hidden -> output layer)\n",
    "        self.fc_output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Select activation function based on the input string\n",
    "        if activ_type.startswith(\"t\"):\n",
    "            self.activ_f = nn.Tanh()  # Hyperbolic tangent activation function\n",
    "        elif activ_type.startswith(\"l\"):\n",
    "            self.activ_f = nn.LeakyReLU(alpha)  # LeakyReLU activation function with specified alpha\n",
    "        elif activ_type.startswith(\"r\"):\n",
    "            self.activ_f = nn.ReLU()  # ReLU activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output of the network after passing through all layers and activations.\n",
    "        \"\"\"\n",
    "        # Apply the activation function to the input layer\n",
    "        x = self.activ_f(self.fc_input(x))\n",
    "\n",
    "        # Apply the activation function for each hidden layer\n",
    "        for i in range(len(self.fc_hidden)):\n",
    "            x = self.activ_f(self.fc_hidden[i](x))\n",
    "\n",
    "        # Pass through the output layer and apply the linear function\n",
    "        x = self.fc_output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data_loader, model, learning_rate, momentum, weight_decay, epochs, patience, optim_type = 'SGD', reg_flag = False, val_data=[], val_labels=[]):\n",
    "    \"\"\"\n",
    "    Trains a neural network model with optional regularization and early stopping.\n",
    "\n",
    "    Args:\n",
    "        data_loader (DataLoader): DataLoader for training data.\n",
    "        model (nn.Module): The neural network model to train.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        momentum (float): Momentum value for the optimizer.\n",
    "        weight_decay (float): Weight decay (L2 regularization) value.\n",
    "        epochs (int): Number of training epochs.\n",
    "        patience (int): Patience for early stopping.\n",
    "        optim_type (str, optional): Optimizer type ('SGD' or 'Adam'). Default is 'SGD'.\n",
    "        reg_flag (bool, optional): Whether to apply regularization. Default is False.\n",
    "        val_data (list, optional): Validation data inputs. Default is an empty list.\n",
    "        val_labels (list, optional): Validation data labels. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the training history (loss and accuracy for both train and validation).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the loss function (Mean Squared Error Loss)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Set the optimizer based on the selected configuration\n",
    "    if reg_flag:\n",
    "        # If regularization is enabled, include weight decay in the optimizer\n",
    "        if optim_type == 'Adam':\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "        else:\n",
    "            optimizer = optim.SGD(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "    else:\n",
    "        # If regularization is not enabled, omit weight decay\n",
    "        if optim_type == 'Adam':\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True \n",
    "            )\n",
    "        else:\n",
    "            optimizer = optim.SGD(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True \n",
    "            )\n",
    "\n",
    "    # Initialize a dictionary to track training and validation performance\n",
    "    history = {'train_loss': [], 'train_mee': [], 'val_loss': [], 'val_mee': []}\n",
    "    \n",
    "    # Create an early stopping object to prevent overfitting\n",
    "    early_stopping = EarlyStopping(patience, delta = 0.05, verbose=False)\n",
    "    \n",
    "    # Training loop for the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        total_mee = 0  # Initialize total Mean Euclidean Error (MEE) for the epoch\n",
    "        total_samples = 0  # Initialize total number of samples processed\n",
    "        last_loss = 0  # Variable to store the last loss for the epoch\n",
    "        \n",
    "        # Iterate over batches in the training data\n",
    "        for inputs, labels in data_loader:\n",
    "            optimizer.zero_grad()  # Reset gradients before the backward pass\n",
    "            outputs = model(inputs)  # Perform a forward pass through the model\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # Compute the loss between predictions and true labels\n",
    "            loss.backward()  # Perform backpropagation to compute gradients\n",
    "            optimizer.step()  # Update the model parameters using the optimizer\n",
    "\n",
    "            last_loss = loss.item()  # Store the current loss for reporting\n",
    "\n",
    "            # Calculate the Mean Euclidean Error (MEE) for the current batch\n",
    "            batch_mee = torch.norm(outputs - labels.unsqueeze(1), dim=1).mean().item()\n",
    "            total_mee += batch_mee  # Accumulate the MEE for the entire epoch\n",
    "            total_samples += labels.size(0)  # Count the number of samples processed\n",
    "\n",
    "        # Calculate the mean MEE for the entire epoch\n",
    "        mean_mee_epoch = total_mee / total_samples\n",
    "        history['train_loss'].append(last_loss)  # Record the training loss for the epoch\n",
    "        history['train_mee'].append(mean_mee_epoch)  # Record the mean MEE for the epoch\n",
    "\n",
    "        # Validation for the current epoch (if validation data is provided)\n",
    "        if val_data is not None and val_labels is not None and len(val_data) > 0 and len(val_labels) > 0:\n",
    "            result = evaluation(model, val_data, val_labels, criterion)  # Evaluate on validation set\n",
    "            history['val_loss'].append(result[0])  # Record the validation loss\n",
    "            history['val_mee'].append(result[1])  # Record the validation MEE\n",
    "            early_stopping(result[0], model)  # Apply early stopping based on validation loss\n",
    "            if early_stopping.early_stop:\n",
    "                #print(\"Early stopping triggered!\")  # Print message when early stopping is triggered\n",
    "                break  # Stop training if early stopping criteria are met\n",
    "\n",
    "    return history  # Return the training history\n",
    "\n",
    "def evaluation(model, X, Y, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate.\n",
    "        X (list or array-like): Input data.\n",
    "        Y (list or array-like): Labels for the input data.\n",
    "        criterion (nn.Module): Loss function to compute the loss.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing validation loss and MEE.\n",
    "    \"\"\"\n",
    "\n",
    "    total_mee = 0  # Initialize total MEE for evaluation\n",
    "    total_samples = 0  # Initialize total number of samples evaluated\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation (saves memory and computations)\n",
    "        inputs = torch.tensor(X, dtype=torch.float32)  # Convert input data to tensor\n",
    "        labels = torch.tensor(Y, dtype=torch.float32)  # Convert labels to tensor\n",
    "        outputs = model(inputs)  # Perform a forward pass through the model\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))  # Calculate the loss (e.g., MSE loss)\n",
    "        \n",
    "        # Calculate the Mean Euclidean Error (MEE) for the validation data\n",
    "        batch_mee = torch.norm(outputs - labels.unsqueeze(1), dim=1).mean().item()\n",
    "        total_mee += batch_mee  # Accumulate the MEE\n",
    "        total_samples += labels.size(0)  # Count the number of validation samples\n",
    "\n",
    "        # Compute the mean MEE for the entire validation set\n",
    "        mean_mee_epoch = total_mee / total_samples\n",
    "        return [loss.item(), mean_mee_epoch]  # Return loss and MEE for the validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double-k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_k_fold_cross_validation(data, labels, activ_type = 'tanh', optim_type = 'SGD',\n",
    "                                   reg_flag = False, input_size = 12, output_size = 3, outer_k = 5, inner_k = 5, param_grid=None):\n",
    "    \"\"\"\n",
    "    Implements Double K-Fold Cross-Validation\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "     -   data (np.ndarray): Features of the dataset.\n",
    "     -   labels (np.ndarray): Labels of the dataset.\n",
    "     -   activ_type (str): Activation function type.\n",
    "     -   optim_type (str): Optimizer type.\n",
    "     -   reg_flag (bool): Regularization flag.\n",
    "     -  in_size (int): Input size.\n",
    "     -   outer_k (int): Number of folds for outer cross-validation.\n",
    "     -   inner_k (int): Number of folds for inner cross-validation.\n",
    "     -   param_grid (list): List of dictionaries with hyperparameters to try.\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "     -   list: List of scores obtained for each outer fold.\n",
    "     -   list: List of best parameters for each outer fold.\n",
    "    \"\"\"\n",
    "    outer_scores = []\n",
    "    outer_params = []\n",
    "    \n",
    "    # Configuration of the outer k-fold cross-validation\n",
    "    out_kfold = KFold(n_splits=outer_k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Outer cross-validation loop\n",
    "    out_fold_no = 1\n",
    "    for train_index, val_index in out_kfold.split(data, labels):\n",
    "        \n",
    "        # Split the dataset into training and validation sets for the outer fold\n",
    "        out_X_train, out_X_val = data[train_index], data[val_index]\n",
    "        out_y_train, out_y_val = labels[train_index], labels[val_index]\n",
    "        \n",
    "        best_params = {}\n",
    "        best_score = -np.inf\n",
    "\n",
    "        # Iterate over each set of hyperparameters in the parameter grid\n",
    "        for params in param_grid:\n",
    "\n",
    "            inner_scores = []\n",
    "\n",
    "            # Inner cross-validation loop\n",
    "            inner_fold_no = 1\n",
    "            inner_kfold = KFold(n_splits=inner_k, shuffle=True, random_state=42)\n",
    "\n",
    "            for train_index, val_index in inner_kfold.split(out_X_train, out_y_train):\n",
    "                \n",
    "                # Split the dataset into training and validation sets for the inner fold\n",
    "                inner_X_train, inner_X_val = out_X_train[train_index], out_X_train[val_index]\n",
    "                inner_y_train, inner_y_val = out_y_train[train_index], out_y_train[val_index]\n",
    "\n",
    "                # Create a custom dataset using the training data (features and labels)\n",
    "                dataset = CustomDataset(inner_X_train, inner_y_train)\n",
    "\n",
    "                # Initialize a DataLoader to iterate over the dataset in mini-batches\n",
    "                # - batch_size: Size of each batch, taken from the 'params' dictionary\n",
    "                # - shuffle: Set to False to maintain the original order of the data\n",
    "                data_loader = DataLoader(dataset, batch_size=int(params['batch_size']), shuffle=False)\n",
    "\n",
    "                # Create the neural network model\n",
    "                model = NN(input_size = input_size, hidden_size = params['hidden_size'], output_size = output_size,\n",
    "                           hidden_layers = params['hidden_layers'], alpha=params['alpha'], activ_type = activ_type)\n",
    "                \n",
    "                # Train the model and obtain the history\n",
    "                history = fit(data_loader=data_loader, model=model, learning_rate=params['learning_rate'], \n",
    "                              weight_decay=params['regularization'], momentum=params['momentum'],\n",
    "                              epochs=params['epochs'], patience = params['patience'], optim_type = optim_type, reg_flag = reg_flag, val_data=inner_X_val, val_labels=inner_y_val)\n",
    "\n",
    "                # Append the minimum validation MEE to inner scores\n",
    "                inner_scores.append(min(history['val_mee']))\n",
    "                inner_fold_no += 1\n",
    "            \n",
    "            # Calculate the average score for the current set of hyperparameters\n",
    "            avg_score = np.mean(inner_scores)\n",
    "\n",
    "            # Update the best score and parameters if the current average score is better\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = params\n",
    "        \n",
    "\n",
    "        # Train the final model on the outer training set with the best hyperparameters\n",
    "        dataset = CustomDataset(out_X_train, out_y_train)\n",
    "        data_loader = DataLoader(dataset, batch_size=int(params['batch_size']), shuffle=False)\n",
    "\n",
    "        final_model = NN(input_size = input_size, hidden_size = params['hidden_size'], output_size = output_size, \n",
    "                         hidden_layers = params['hidden_layers'], alpha=params['alpha'], activ_type = activ_type)\n",
    "        \n",
    "        history = fit(data_loader=data_loader, model=final_model, learning_rate=params['learning_rate'], \n",
    "                      weight_decay=params['regularization'], momentum=params['momentum'],\n",
    "                      epochs=params['epochs'], patience = params['patience'], optim_type = optim_type, reg_flag = reg_flag, val_data=out_X_val, val_labels=out_y_val)\n",
    "        \n",
    "        # Append the maximum validation MEE to outer scores\n",
    "        outer_scores.append(min(history['val_mee']))\n",
    "        outer_params.append(best_params)\n",
    "\n",
    "        out_fold_no += 1\n",
    "    \n",
    "    return outer_scores, outer_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data, labels, activ_type = 'tanh', optim_type = 'SGD', reg_flag = False, input_size =12, output_size = 3, params=None):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation on the given dataset using a neural network model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - data (np.ndarray): Features of the dataset.\n",
    "    - labels (np.ndarray): Labels of the dataset.\n",
    "    - activ_type (str): Activation function type for hidden layers.\n",
    "    - optim_type (str): Optimizer type ('SGD' or 'Adam').\n",
    "    - reg_flag (bool): Flag to indicate whether to use L2 regularization.\n",
    "    - in_size (int): Number of input features.\n",
    "    - params (dict): Dictionary containing hyperparameters for the model.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    - avg_score (float): Average validation MEE across all folds.\n",
    "    - history (tf.keras.callbacks.History): Training history of the final model.\n",
    "    - model (tf.keras.Model): Trained Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Configuration of k-fold cross-validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Cross-validation loop\n",
    "    fold_no = 1\n",
    "    mee_per_fold = []\n",
    "    for train_index, val_index in kfold.split(data, labels):\n",
    "        \n",
    "        # Split the dataset into training and validation sets for the current fold\n",
    "        X_train, X_val = data[train_index], data[val_index]\n",
    "        y_train, y_val = labels[train_index], labels[val_index]\n",
    "        \n",
    "\n",
    "        dataset = CustomDataset(X_train, y_train)\n",
    "        data_loader = DataLoader(dataset, batch_size=int(params['batch_size']), shuffle=False)\n",
    "\n",
    "        # Create the neural network model\n",
    "        model = NN(input_size = input_size,\n",
    "                    hidden_size = params['hidden_size'],\n",
    "                    output_size = output_size,\n",
    "                    hidden_layers = params['hidden_layers'], \n",
    "                    alpha=params['alpha'],\n",
    "                    activ_type = activ_type)\n",
    "        \n",
    "        \n",
    "        # Train the model and obtain the histor\n",
    "        history = fit(data_loader=data_loader, model=model, learning_rate=params['learning_rate'], \n",
    "                      weight_decay=params['regularization'], momentum=params['momentum'],\n",
    "                      epochs=params['epochs'], patience = params['patience'], optim_type = optim_type, reg_flag = reg_flag, val_data=X_val, val_labels=y_val)\n",
    "        \n",
    "\n",
    "        # Get the best score (minimum validation MEE)\n",
    "        score = min(history['val_mee'])\n",
    "        mee_per_fold.append(score)\n",
    "        fold_no += 1\n",
    "\n",
    "    # Calculate the average score across all folds\n",
    "    avg_score = np.mean(mee_per_fold)\n",
    "\n",
    "    # Split the dataset into training and validation sets for the final training\n",
    "    X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create the neural network model for the final training\n",
    "    dataset = CustomDataset(X_train, y_train)\n",
    "    data_loader = DataLoader(dataset, batch_size=int(params['batch_size']), shuffle=False)\n",
    "\n",
    "    model = NN(input_size = input_size, hidden_size = params['hidden_size'], output_size = output_size,\n",
    "               hidden_layers = params['hidden_layers'], alpha=params['alpha'], activ_type = activ_type)\n",
    "        \n",
    "    history = fit(data_loader=data_loader, model=model, learning_rate=params['learning_rate'], \n",
    "                      weight_decay=params['regularization'], momentum=params['momentum'],\n",
    "                      epochs=params['epochs'], patience = params['patience'], optim_type = optim_type, reg_flag = reg_flag, val_data=X_val, val_labels=y_val)\n",
    "\n",
    "    # Return the average score, training history, and the final model\n",
    "    return avg_score, history, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_path = '../Datasets/CUP/ML-CUP24-TR.csv'  # Path to the training dataset\n",
    "test_path = '../Datasets/CUP/ML-CUP24-TS.csv'   # Path to the test dataset\n",
    "data_train = pd.read_csv(train_path, skiprows=7)  # Load the training data, skipping the first 7 rows\n",
    "data_blind_test = pd.read_csv(test_path, skiprows=7)    # Load the test data, skipping the first 7 rows\n",
    "\n",
    "# Drop the ID column and split inputs/outputs for training data\n",
    "X_train = data_train.iloc[:, 1:-3].values  # Extract input features (all columns except the first and last three)\n",
    "y_train = data_train.iloc[:, -3:].values   # Extract target values (last three columns: TARGET_x, TARGET_y, TARGET_z)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Drop the ID column and split inputs/outputs for test data\n",
    "X_blind_test = data_blind_test.iloc[:, 1:].values  # Extract input features (all columns except the first)\n",
    "\n",
    "# Standardize inputs (mean 0, std 1)\n",
    "input_scaler = StandardScaler()  # Initialize the StandardScaler for input features\n",
    "X_train_scaled = input_scaler.fit_transform(X_train)  # Fit the scaler on training data and transform it\n",
    "X_test_scaled = input_scaler.transform(X_test)  \n",
    "X_blind_test_scaled = input_scaler.transform(X_blind_test)        # Transform the test data using the same scaler\n",
    "\n",
    "# Normalize outputs (Min-Max scaling to [0, 1])\n",
    "output_scaler = MinMaxScaler()  # Initialize the MinMaxScaler for output values\n",
    "y_train_scaled = output_scaler.fit_transform(y_train)  # Fit the scaler on training target values and transform them\n",
    "y_test_scaled = output_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greed_search(data, labels, activ_type = 'tanh', optim_type = 'SGD', reg_flag = False, input_size = 12, output_size = 3, param_grid = None):\n",
    "    \"\"\"\n",
    "    Perform a greedy search over the hyperparameter grid to find the best model configurations.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - data (np.ndarray): Features of the dataset.\n",
    "    - labels (np.ndarray): Labels of the dataset.\n",
    "    - activ_type (str): Activation function type for hidden layers.\n",
    "    - optim_type (str): Optimizer type ('SGD' or 'Adam').\n",
    "    - reg_flag (bool): Flag to indicate whether to use L2 regularization.\n",
    "    - input_size (int): Number of input features.\n",
    "    - param_grid (list): List of dictionaries with hyperparameters to try.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    - best_scores (list): List of the best scores obtained.\n",
    "    - best_params_list (list): List of the best hyperparameter configurations.\n",
    "    - best_models (list): List of the best trained models.\n",
    "    - best_histories (list): List of the training histories of the best models.\n",
    "    \"\"\"\n",
    "    \n",
    "    best_scores = []  # List to store the best scores\n",
    "    best_params_list = []  # List to store the best hyperparameter configurations\n",
    "    best_models = []  # List to store the best models\n",
    "    best_histories = []  # List to store the training histories of the best models\n",
    "\n",
    "    # Iterate over each set of hyperparameters in the parameter grid\n",
    "    for params in param_grid:\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"Testing params: {params}\")\n",
    "\n",
    "        # Perform k-fold cross-validation with the current set of hyperparameters\n",
    "        score, history, model = k_fold_cross_validation(data, labels, activ_type, optim_type, reg_flag, input_size = input_size, output_size=output_size, params=params)\n",
    "        print(f\"Score : {score}\")\n",
    "\n",
    "        # Add the results to the lists\n",
    "        best_scores.append(score)\n",
    "        best_params_list.append(params)\n",
    "        best_models.append(model)\n",
    "        best_histories.append(history)\n",
    "\n",
    "        # Sort the scores in ascending order and keep the top 10\n",
    "        sorted_indices = np.argsort(best_scores)  \n",
    "        best_scores = [best_scores[i] for i in sorted_indices][:10]  # Keep the top 10 scores\n",
    "        best_params_list = [best_params_list[i] for i in sorted_indices][:10]  # Keep the top 10 hyperparameter configurations\n",
    "        best_models = [best_models[i] for i in sorted_indices][:10]  # Keep the top 10 models\n",
    "        best_histories = [best_histories[i] for i in sorted_indices][:10]  # Keep the top 10 training histories\n",
    "\n",
    "    print(\"--------------------END GREED SEARCH------------------------------\")\n",
    "\n",
    "    # Return the top 10 best results\n",
    "    #print(\"Top 10 best scores:\")\n",
    "    #print(best_scores)\n",
    "    #print(\"Top 10 best params:\")\n",
    "    #print(best_params_list)\n",
    "\n",
    "    return best_scores, best_params_list, best_models, best_histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generazione delle combinazioni di iperparametri...\n",
      "--------------------------------------------------ML CUP--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 2, 'momentum': 0.2, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.4831\n",
      "Epoch 1, Batch MEE: 3.9406\n",
      "Epoch 1, Batch MEE: 6.4049\n",
      "Epoch 1, Batch MEE: 3.8810\n",
      "Epoch 1, Batch MEE: 7.0370\n",
      "Epoch 1, Batch MEE: 4.3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([128, 1, 3])) that is different to the input size (torch.Size([128, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([51, 1, 3])) that is different to the input size (torch.Size([51, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([45, 1, 3])) that is different to the input size (torch.Size([45, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch MEE: 4.9523\n",
      "Epoch 1, Batch MEE: 2.8524\n",
      "Epoch 1, Batch MEE: 6.2771\n",
      "Epoch 1, Batch MEE: 3.7187\n",
      "Epoch 1, Batch MEE: 5.3439\n",
      "Epoch 1, Batch MEE: 3.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([52, 1, 3])) that is different to the input size (torch.Size([52, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([44, 1, 3])) that is different to the input size (torch.Size([44, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.03611607604556613\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 2, 'momentum': 0.30000000000000004, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.8994\n",
      "Epoch 1, Batch MEE: 3.5627\n",
      "Epoch 1, Batch MEE: 6.1605\n",
      "Epoch 1, Batch MEE: 3.8865\n",
      "Epoch 1, Batch MEE: 6.9578\n",
      "Epoch 1, Batch MEE: 4.2271\n",
      "Epoch 1, Batch MEE: 5.9853\n",
      "Epoch 1, Batch MEE: 3.5653\n",
      "Epoch 1, Batch MEE: 7.0064\n",
      "Epoch 1, Batch MEE: 4.2476\n",
      "Epoch 1, Batch MEE: 5.8548\n",
      "Epoch 1, Batch MEE: 3.5577\n",
      "Score : 0.034726566389353584\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 2, 'momentum': 0.4000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 4.6000\n",
      "Epoch 1, Batch MEE: 2.7256\n",
      "Epoch 1, Batch MEE: 7.3873\n",
      "Epoch 1, Batch MEE: 4.7157\n",
      "Epoch 1, Batch MEE: 5.8566\n",
      "Epoch 1, Batch MEE: 3.7315\n",
      "Epoch 1, Batch MEE: 4.7740\n",
      "Epoch 1, Batch MEE: 2.9944\n",
      "Epoch 1, Batch MEE: 5.6368\n",
      "Epoch 1, Batch MEE: 3.3624\n",
      "Epoch 1, Batch MEE: 6.5137\n",
      "Epoch 1, Batch MEE: 4.0983\n",
      "Score : 0.034299755012146146\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 2, 'momentum': 0.5000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.6542\n",
      "Epoch 1, Batch MEE: 4.1979\n",
      "Epoch 1, Batch MEE: 4.7977\n",
      "Epoch 1, Batch MEE: 2.9211\n",
      "Epoch 1, Batch MEE: 5.3047\n",
      "Epoch 1, Batch MEE: 3.3471\n",
      "Epoch 1, Batch MEE: 5.1101\n",
      "Epoch 1, Batch MEE: 3.0588\n",
      "Epoch 1, Batch MEE: 6.0775\n",
      "Epoch 1, Batch MEE: 3.6773\n",
      "Epoch 1, Batch MEE: 6.3700\n",
      "Epoch 1, Batch MEE: 4.1042\n",
      "Score : 0.03450524115803266\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 2, 'momentum': 0.6000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.6411\n",
      "Epoch 1, Batch MEE: 4.0905\n",
      "Epoch 1, Batch MEE: 6.6660\n",
      "Epoch 1, Batch MEE: 4.0351\n",
      "Epoch 1, Batch MEE: 6.3128\n",
      "Epoch 1, Batch MEE: 3.8762\n",
      "Epoch 1, Batch MEE: 5.9609\n",
      "Epoch 1, Batch MEE: 3.6430\n",
      "Epoch 1, Batch MEE: 7.5731\n",
      "Epoch 1, Batch MEE: 4.5979\n",
      "Epoch 1, Batch MEE: 5.9819\n",
      "Epoch 1, Batch MEE: 3.4906\n",
      "Score : 0.03255019560004725\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 2, 'momentum': 0.7000000000000002, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.9400\n",
      "Epoch 1, Batch MEE: 3.5903\n",
      "Epoch 1, Batch MEE: 5.2087\n",
      "Epoch 1, Batch MEE: 3.4395\n",
      "Epoch 1, Batch MEE: 5.8166\n",
      "Epoch 1, Batch MEE: 3.4913\n",
      "Epoch 1, Batch MEE: 7.4345\n",
      "Epoch 1, Batch MEE: 4.3589\n",
      "Epoch 1, Batch MEE: 5.9305\n",
      "Epoch 1, Batch MEE: 3.8166\n",
      "Epoch 1, Batch MEE: 6.8813\n",
      "Epoch 1, Batch MEE: 4.2008\n",
      "Score : 0.0318126479905061\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 2, 'momentum': 0.8000000000000003, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.8393\n",
      "Epoch 1, Batch MEE: 3.5639\n",
      "Epoch 1, Batch MEE: 5.0872\n",
      "Epoch 1, Batch MEE: 2.9843\n",
      "Epoch 1, Batch MEE: 6.4388\n",
      "Epoch 1, Batch MEE: 3.7281\n",
      "Epoch 1, Batch MEE: 4.9930\n",
      "Epoch 1, Batch MEE: 3.0232\n",
      "Epoch 1, Batch MEE: 6.1698\n",
      "Epoch 1, Batch MEE: 3.7525\n",
      "Epoch 1, Batch MEE: 5.7565\n",
      "Epoch 1, Batch MEE: 3.5344\n",
      "Score : 0.031191437148084544\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 3, 'momentum': 0.2, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 4.4917\n",
      "Epoch 1, Batch MEE: 2.7317\n",
      "Epoch 1, Batch MEE: 4.7544\n",
      "Epoch 1, Batch MEE: 2.8297\n",
      "Epoch 1, Batch MEE: 5.9659\n",
      "Epoch 1, Batch MEE: 3.5916\n",
      "Epoch 1, Batch MEE: 6.5304\n",
      "Epoch 1, Batch MEE: 4.0210\n",
      "Epoch 1, Batch MEE: 7.3324\n",
      "Epoch 1, Batch MEE: 4.5365\n",
      "Epoch 1, Batch MEE: 5.5631\n",
      "Epoch 1, Batch MEE: 3.5127\n",
      "Score : 0.03580052930899341\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 3, 'momentum': 0.30000000000000004, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.7309\n",
      "Epoch 1, Batch MEE: 3.5570\n",
      "Epoch 1, Batch MEE: 6.8624\n",
      "Epoch 1, Batch MEE: 4.2600\n",
      "Epoch 1, Batch MEE: 6.6997\n",
      "Epoch 1, Batch MEE: 4.1919\n",
      "Epoch 1, Batch MEE: 7.2898\n",
      "Epoch 1, Batch MEE: 4.3007\n",
      "Epoch 1, Batch MEE: 5.5160\n",
      "Epoch 1, Batch MEE: 3.3747\n",
      "Epoch 1, Batch MEE: 7.0077\n",
      "Epoch 1, Batch MEE: 4.4106\n",
      "Score : 0.03372521638870239\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 3, 'momentum': 0.4000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.0655\n",
      "Epoch 1, Batch MEE: 3.7589\n",
      "Epoch 1, Batch MEE: 6.4301\n",
      "Epoch 1, Batch MEE: 3.8595\n",
      "Epoch 1, Batch MEE: 4.5470\n",
      "Epoch 1, Batch MEE: 2.7481\n",
      "Epoch 1, Batch MEE: 6.9072\n",
      "Epoch 1, Batch MEE: 4.1909\n",
      "Epoch 1, Batch MEE: 5.1471\n",
      "Epoch 1, Batch MEE: 3.1726\n",
      "Epoch 1, Batch MEE: 5.8943\n",
      "Epoch 1, Batch MEE: 3.6841\n",
      "Score : 0.034282335693185985\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 3, 'momentum': 0.5000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 7.0365\n",
      "Epoch 1, Batch MEE: 4.4331\n",
      "Epoch 1, Batch MEE: 5.6636\n",
      "Epoch 1, Batch MEE: 3.4677\n",
      "Epoch 1, Batch MEE: 5.6852\n",
      "Epoch 1, Batch MEE: 3.5157\n",
      "Epoch 1, Batch MEE: 6.7390\n",
      "Epoch 1, Batch MEE: 3.9955\n",
      "Epoch 1, Batch MEE: 5.2326\n",
      "Epoch 1, Batch MEE: 3.1650\n",
      "Epoch 1, Batch MEE: 5.2047\n",
      "Epoch 1, Batch MEE: 3.2547\n",
      "Score : 0.032914997977439804\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 3, 'momentum': 0.6000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.4493\n",
      "Epoch 1, Batch MEE: 3.3477\n",
      "Epoch 1, Batch MEE: 6.7120\n",
      "Epoch 1, Batch MEE: 4.0825\n",
      "Epoch 1, Batch MEE: 7.1571\n",
      "Epoch 1, Batch MEE: 4.4796\n",
      "Epoch 1, Batch MEE: 6.2133\n",
      "Epoch 1, Batch MEE: 3.7437\n",
      "Epoch 1, Batch MEE: 5.0447\n",
      "Epoch 1, Batch MEE: 3.0473\n",
      "Epoch 1, Batch MEE: 6.7843\n",
      "Epoch 1, Batch MEE: 4.1905\n",
      "Score : 0.0316500571641055\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 3, 'momentum': 0.7000000000000002, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.0736\n",
      "Epoch 1, Batch MEE: 3.7514\n",
      "Epoch 1, Batch MEE: 6.9863\n",
      "Epoch 1, Batch MEE: 4.1521\n",
      "Epoch 1, Batch MEE: 3.8607\n",
      "Epoch 1, Batch MEE: 2.2993\n",
      "Epoch 1, Batch MEE: 5.3117\n",
      "Epoch 1, Batch MEE: 3.0753\n",
      "Epoch 1, Batch MEE: 5.0838\n",
      "Epoch 1, Batch MEE: 3.0433\n",
      "Epoch 1, Batch MEE: 6.2071\n",
      "Epoch 1, Batch MEE: 3.8678\n",
      "Score : 0.03129519608285693\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 30, 'hidden_layers': 3, 'momentum': 0.8000000000000003, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 7.2843\n",
      "Epoch 1, Batch MEE: 4.4756\n",
      "Epoch 1, Batch MEE: 5.4465\n",
      "Epoch 1, Batch MEE: 3.4067\n",
      "Epoch 1, Batch MEE: 5.7818\n",
      "Epoch 1, Batch MEE: 3.4329\n",
      "Epoch 1, Batch MEE: 5.5884\n",
      "Epoch 1, Batch MEE: 3.3861\n",
      "Epoch 1, Batch MEE: 5.7974\n",
      "Epoch 1, Batch MEE: 3.5261\n",
      "Epoch 1, Batch MEE: 5.6046\n",
      "Epoch 1, Batch MEE: 3.5449\n",
      "Score : 0.029755117640350805\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 2, 'momentum': 0.2, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.1335\n",
      "Epoch 1, Batch MEE: 3.8924\n",
      "Epoch 1, Batch MEE: 5.9861\n",
      "Epoch 1, Batch MEE: 3.6926\n",
      "Epoch 1, Batch MEE: 5.8763\n",
      "Epoch 1, Batch MEE: 3.5243\n",
      "Epoch 1, Batch MEE: 5.2416\n",
      "Epoch 1, Batch MEE: 3.0723\n",
      "Epoch 1, Batch MEE: 6.9120\n",
      "Epoch 1, Batch MEE: 4.2435\n",
      "Epoch 1, Batch MEE: 6.2551\n",
      "Epoch 1, Batch MEE: 3.8959\n",
      "Score : 0.03730220781432257\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 2, 'momentum': 0.30000000000000004, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.9329\n",
      "Epoch 1, Batch MEE: 4.2532\n",
      "Epoch 1, Batch MEE: 6.0607\n",
      "Epoch 1, Batch MEE: 3.7001\n",
      "Epoch 1, Batch MEE: 6.2397\n",
      "Epoch 1, Batch MEE: 3.9662\n",
      "Epoch 1, Batch MEE: 5.8938\n",
      "Epoch 1, Batch MEE: 3.6314\n",
      "Epoch 1, Batch MEE: 5.9615\n",
      "Epoch 1, Batch MEE: 3.7262\n",
      "Epoch 1, Batch MEE: 4.6544\n",
      "Epoch 1, Batch MEE: 2.9813\n",
      "Score : 0.03577964705650252\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 2, 'momentum': 0.4000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.1284\n",
      "Epoch 1, Batch MEE: 3.8545\n",
      "Epoch 1, Batch MEE: 5.7740\n",
      "Epoch 1, Batch MEE: 3.5602\n",
      "Epoch 1, Batch MEE: 6.1364\n",
      "Epoch 1, Batch MEE: 3.9891\n",
      "Epoch 1, Batch MEE: 6.0906\n",
      "Epoch 1, Batch MEE: 3.6581\n",
      "Epoch 1, Batch MEE: 6.2457\n",
      "Epoch 1, Batch MEE: 3.7139\n",
      "Epoch 1, Batch MEE: 6.2706\n",
      "Epoch 1, Batch MEE: 3.9078\n",
      "Score : 0.03355654468440046\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 2, 'momentum': 0.5000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.4253\n",
      "Epoch 1, Batch MEE: 3.3391\n",
      "Epoch 1, Batch MEE: 5.2701\n",
      "Epoch 1, Batch MEE: 3.1615\n",
      "Epoch 1, Batch MEE: 6.1109\n",
      "Epoch 1, Batch MEE: 3.9205\n",
      "Epoch 1, Batch MEE: 5.9560\n",
      "Epoch 1, Batch MEE: 3.5859\n",
      "Epoch 1, Batch MEE: 6.5346\n",
      "Epoch 1, Batch MEE: 4.1097\n",
      "Epoch 1, Batch MEE: 5.6273\n",
      "Epoch 1, Batch MEE: 3.4586\n",
      "Score : 0.03299656758404741\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 2, 'momentum': 0.6000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.5783\n",
      "Epoch 1, Batch MEE: 3.4538\n",
      "Epoch 1, Batch MEE: 5.0138\n",
      "Epoch 1, Batch MEE: 3.0598\n",
      "Epoch 1, Batch MEE: 4.5397\n",
      "Epoch 1, Batch MEE: 2.8947\n",
      "Epoch 1, Batch MEE: 5.6308\n",
      "Epoch 1, Batch MEE: 3.2971\n",
      "Epoch 1, Batch MEE: 5.9997\n",
      "Epoch 1, Batch MEE: 3.5680\n",
      "Epoch 1, Batch MEE: 6.0877\n",
      "Epoch 1, Batch MEE: 3.7948\n",
      "Score : 0.032731575809343896\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 2, 'momentum': 0.7000000000000002, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.8347\n",
      "Epoch 1, Batch MEE: 4.4335\n",
      "Epoch 1, Batch MEE: 5.4050\n",
      "Epoch 1, Batch MEE: 3.1825\n",
      "Epoch 1, Batch MEE: 5.8873\n",
      "Epoch 1, Batch MEE: 3.6025\n",
      "Epoch 1, Batch MEE: 5.2342\n",
      "Epoch 1, Batch MEE: 3.0223\n",
      "Epoch 1, Batch MEE: 5.4816\n",
      "Epoch 1, Batch MEE: 3.3643\n",
      "Epoch 1, Batch MEE: 6.4157\n",
      "Epoch 1, Batch MEE: 3.8584\n",
      "Score : 0.03123019985478334\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 2, 'momentum': 0.8000000000000003, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.5640\n",
      "Epoch 1, Batch MEE: 3.3932\n",
      "Epoch 1, Batch MEE: 6.3783\n",
      "Epoch 1, Batch MEE: 3.8218\n",
      "Epoch 1, Batch MEE: 6.4027\n",
      "Epoch 1, Batch MEE: 3.7770\n",
      "Epoch 1, Batch MEE: 4.4433\n",
      "Epoch 1, Batch MEE: 2.6531\n",
      "Epoch 1, Batch MEE: 5.9086\n",
      "Epoch 1, Batch MEE: 3.4742\n",
      "Epoch 1, Batch MEE: 4.7161\n",
      "Epoch 1, Batch MEE: 2.8391\n",
      "Score : 0.030516105637405855\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 3, 'momentum': 0.2, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 4.9891\n",
      "Epoch 1, Batch MEE: 3.0944\n",
      "Epoch 1, Batch MEE: 4.9948\n",
      "Epoch 1, Batch MEE: 3.0740\n",
      "Epoch 1, Batch MEE: 4.9621\n",
      "Epoch 1, Batch MEE: 2.9541\n",
      "Epoch 1, Batch MEE: 6.4061\n",
      "Epoch 1, Batch MEE: 3.9067\n",
      "Epoch 1, Batch MEE: 5.5846\n",
      "Epoch 1, Batch MEE: 3.3186\n",
      "Epoch 1, Batch MEE: 4.3667\n",
      "Epoch 1, Batch MEE: 2.7866\n",
      "Score : 0.03576430305086001\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 3, 'momentum': 0.30000000000000004, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.9954\n",
      "Epoch 1, Batch MEE: 3.6862\n",
      "Epoch 1, Batch MEE: 5.0318\n",
      "Epoch 1, Batch MEE: 3.0532\n",
      "Epoch 1, Batch MEE: 5.8539\n",
      "Epoch 1, Batch MEE: 3.5234\n",
      "Epoch 1, Batch MEE: 5.9193\n",
      "Epoch 1, Batch MEE: 3.6251\n",
      "Epoch 1, Batch MEE: 6.0791\n",
      "Epoch 1, Batch MEE: 3.6691\n",
      "Epoch 1, Batch MEE: 5.5666\n",
      "Epoch 1, Batch MEE: 3.3883\n",
      "Score : 0.033799630331270626\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 3, 'momentum': 0.4000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.4587\n",
      "Epoch 1, Batch MEE: 3.9809\n",
      "Epoch 1, Batch MEE: 5.5234\n",
      "Epoch 1, Batch MEE: 3.3588\n",
      "Epoch 1, Batch MEE: 7.2369\n",
      "Epoch 1, Batch MEE: 4.3711\n",
      "Epoch 1, Batch MEE: 5.1836\n",
      "Epoch 1, Batch MEE: 3.1772\n",
      "Epoch 1, Batch MEE: 6.9882\n",
      "Epoch 1, Batch MEE: 4.2392\n",
      "Epoch 1, Batch MEE: 6.1437\n",
      "Epoch 1, Batch MEE: 3.7862\n",
      "Score : 0.032104075340309526\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 3, 'momentum': 0.5000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.9586\n",
      "Epoch 1, Batch MEE: 3.6029\n",
      "Epoch 1, Batch MEE: 5.6347\n",
      "Epoch 1, Batch MEE: 3.3897\n",
      "Epoch 1, Batch MEE: 5.3874\n",
      "Epoch 1, Batch MEE: 3.4134\n",
      "Epoch 1, Batch MEE: 6.5389\n",
      "Epoch 1, Batch MEE: 3.8866\n",
      "Epoch 1, Batch MEE: 5.2463\n",
      "Epoch 1, Batch MEE: 3.2513\n",
      "Epoch 1, Batch MEE: 5.6672\n",
      "Epoch 1, Batch MEE: 3.4653\n",
      "Score : 0.032279463970299925\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 3, 'momentum': 0.6000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 7.1425\n",
      "Epoch 1, Batch MEE: 4.3787\n",
      "Epoch 1, Batch MEE: 6.1368\n",
      "Epoch 1, Batch MEE: 3.7604\n",
      "Epoch 1, Batch MEE: 6.1695\n",
      "Epoch 1, Batch MEE: 3.7324\n",
      "Epoch 1, Batch MEE: 6.0969\n",
      "Epoch 1, Batch MEE: 3.6582\n",
      "Epoch 1, Batch MEE: 6.0515\n",
      "Epoch 1, Batch MEE: 3.6651\n",
      "Epoch 1, Batch MEE: 6.1433\n",
      "Epoch 1, Batch MEE: 3.8727\n",
      "Score : 0.03187359913431033\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 3, 'momentum': 0.7000000000000002, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.9205\n",
      "Epoch 1, Batch MEE: 3.6197\n",
      "Epoch 1, Batch MEE: 6.1081\n",
      "Epoch 1, Batch MEE: 3.7019\n",
      "Epoch 1, Batch MEE: 6.5368\n",
      "Epoch 1, Batch MEE: 4.1051\n",
      "Epoch 1, Batch MEE: 5.0798\n",
      "Epoch 1, Batch MEE: 3.0297\n",
      "Epoch 1, Batch MEE: 6.3600\n",
      "Epoch 1, Batch MEE: 3.8962\n",
      "Epoch 1, Batch MEE: 5.1032\n",
      "Epoch 1, Batch MEE: 3.1398\n",
      "Score : 0.030516661056364424\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 40, 'hidden_layers': 3, 'momentum': 0.8000000000000003, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.5306\n",
      "Epoch 1, Batch MEE: 3.9552\n",
      "Epoch 1, Batch MEE: 5.2475\n",
      "Epoch 1, Batch MEE: 3.1799\n",
      "Epoch 1, Batch MEE: 6.0416\n",
      "Epoch 1, Batch MEE: 3.6759\n",
      "Epoch 1, Batch MEE: 5.0417\n",
      "Epoch 1, Batch MEE: 3.0132\n",
      "Epoch 1, Batch MEE: 6.2225\n",
      "Epoch 1, Batch MEE: 3.7674\n",
      "Epoch 1, Batch MEE: 5.6543\n",
      "Epoch 1, Batch MEE: 3.4498\n",
      "Score : 0.030053962143984703\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 50, 'hidden_layers': 2, 'momentum': 0.2, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.7369\n",
      "Epoch 1, Batch MEE: 4.1364\n",
      "Epoch 1, Batch MEE: 5.1492\n",
      "Epoch 1, Batch MEE: 3.0319\n",
      "Epoch 1, Batch MEE: 6.2402\n",
      "Epoch 1, Batch MEE: 3.9156\n",
      "Epoch 1, Batch MEE: 6.5942\n",
      "Epoch 1, Batch MEE: 4.0214\n",
      "Epoch 1, Batch MEE: 5.4488\n",
      "Epoch 1, Batch MEE: 3.3215\n",
      "Epoch 1, Batch MEE: 6.7870\n",
      "Epoch 1, Batch MEE: 4.0438\n",
      "Score : 0.03621599296126703\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 50, 'hidden_layers': 2, 'momentum': 0.30000000000000004, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.3762\n",
      "Epoch 1, Batch MEE: 3.3499\n",
      "Epoch 1, Batch MEE: 6.4032\n",
      "Epoch 1, Batch MEE: 3.8171\n",
      "Epoch 1, Batch MEE: 5.9246\n",
      "Epoch 1, Batch MEE: 3.6245\n",
      "Epoch 1, Batch MEE: 5.8511\n",
      "Epoch 1, Batch MEE: 3.5211\n",
      "Epoch 1, Batch MEE: 6.7358\n",
      "Epoch 1, Batch MEE: 4.2173\n",
      "Epoch 1, Batch MEE: 6.3774\n",
      "Epoch 1, Batch MEE: 4.0117\n",
      "Score : 0.034122518517754295\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 50, 'hidden_layers': 2, 'momentum': 0.4000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.4749\n",
      "Epoch 1, Batch MEE: 4.1429\n",
      "Epoch 1, Batch MEE: 7.3839\n",
      "Epoch 1, Batch MEE: 4.4184\n",
      "Epoch 1, Batch MEE: 6.3575\n",
      "Epoch 1, Batch MEE: 4.0524\n",
      "Epoch 1, Batch MEE: 6.4812\n",
      "Epoch 1, Batch MEE: 3.9783\n",
      "Epoch 1, Batch MEE: 5.5190\n",
      "Epoch 1, Batch MEE: 3.4121\n",
      "Epoch 1, Batch MEE: 6.2380\n",
      "Epoch 1, Batch MEE: 3.8940\n",
      "Score : 0.03428740577264265\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 50, 'hidden_layers': 2, 'momentum': 0.5000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 7.3993\n",
      "Epoch 1, Batch MEE: 4.3596\n",
      "Epoch 1, Batch MEE: 6.4334\n",
      "Epoch 1, Batch MEE: 3.6643\n",
      "Epoch 1, Batch MEE: 6.9660\n",
      "Epoch 1, Batch MEE: 4.5443\n",
      "Epoch 1, Batch MEE: 6.0924\n",
      "Epoch 1, Batch MEE: 3.5920\n",
      "Epoch 1, Batch MEE: 5.5932\n",
      "Epoch 1, Batch MEE: 3.4502\n",
      "Epoch 1, Batch MEE: 6.9417\n",
      "Epoch 1, Batch MEE: 4.3163\n",
      "Score : 0.03387222122664403\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 50, 'hidden_layers': 2, 'momentum': 0.6000000000000001, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.8061\n",
      "Epoch 1, Batch MEE: 4.1920\n",
      "Epoch 1, Batch MEE: 6.2263\n",
      "Epoch 1, Batch MEE: 3.8126\n",
      "Epoch 1, Batch MEE: 5.9270\n",
      "Epoch 1, Batch MEE: 3.8347\n",
      "Epoch 1, Batch MEE: 5.5614\n",
      "Epoch 1, Batch MEE: 3.4095\n",
      "Epoch 1, Batch MEE: 6.4751\n",
      "Epoch 1, Batch MEE: 3.9124\n",
      "Epoch 1, Batch MEE: 5.7353\n",
      "Epoch 1, Batch MEE: 3.6332\n",
      "Score : 0.03205925308092676\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 50, 'hidden_layers': 2, 'momentum': 0.7000000000000002, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 5.9054\n",
      "Epoch 1, Batch MEE: 3.5596\n",
      "Epoch 1, Batch MEE: 6.0138\n",
      "Epoch 1, Batch MEE: 3.6226\n",
      "Epoch 1, Batch MEE: 4.1757\n",
      "Epoch 1, Batch MEE: 2.8663\n",
      "Epoch 1, Batch MEE: 5.8610\n",
      "Epoch 1, Batch MEE: 3.5494\n",
      "Epoch 1, Batch MEE: 5.5216\n",
      "Epoch 1, Batch MEE: 3.4222\n",
      "Epoch 1, Batch MEE: 6.6114\n",
      "Epoch 1, Batch MEE: 4.0603\n",
      "Score : 0.030865718090172974\n",
      "--------------------------------------------------\n",
      "Testing params: {'learning_rate': 0.007, 'epochs': 700, 'batch_size': 128, 'hidden_size': 50, 'hidden_layers': 2, 'momentum': 0.8000000000000003, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Epoch 1, Batch MEE: 6.8223\n",
      "Epoch 1, Batch MEE: 4.2237\n",
      "Epoch 1, Batch MEE: 5.7142\n",
      "Epoch 1, Batch MEE: 3.3947\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[274], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------ML CUP--------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Perform a greedy search over the hyperparameter grid\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m best_scores, best_params_list, best_models, best_histories \u001b[38;5;241m=\u001b[39m \u001b[43mgreed_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                                                                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtanh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSGD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                                                      \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid_monk1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------Plots--------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Iterate over the best histories, parameters, and scores to print and plot the results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[273], line 34\u001b[0m, in \u001b[0;36mgreed_search\u001b[0;34m(data, labels, activ_type, optim_type, reg_flag, input_size, output_size, param_grid)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Perform k-fold cross-validation with the current set of hyperparameters\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m score, history, model \u001b[38;5;241m=\u001b[39m \u001b[43mk_fold_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactiv_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Add the results to the lists\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[271], line 49\u001b[0m, in \u001b[0;36mk_fold_cross_validation\u001b[0;34m(data, labels, activ_type, optim_type, reg_flag, input_size, output_size, params)\u001b[0m\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m NN(input_size \u001b[38;5;241m=\u001b[39m input_size,\n\u001b[1;32m     41\u001b[0m             hidden_size \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     42\u001b[0m             output_size \u001b[38;5;241m=\u001b[39m output_size,\n\u001b[1;32m     43\u001b[0m             hidden_layers \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_layers\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     44\u001b[0m             alpha\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     45\u001b[0m             activ_type \u001b[38;5;241m=\u001b[39m activ_type)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Train the model and obtain the histor\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m              \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregularization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptim_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_flag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Get the best score (minimum validation MEE)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mee\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[269], line 85\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(data_loader, model, learning_rate, momentum, weight_decay, epochs, patience, optim_type, reg_flag, val_data, val_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m last_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Store the current loss for reporting\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Calculate the Mean Euclidean Error (MEE) for the current batch\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m batch_mee \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     86\u001b[0m total_mee \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_mee  \u001b[38;5;66;03m# Accumulate the MEE for the entire epoch\u001b[39;00m\n\u001b[1;32m     87\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Count the number of samples processed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/functional.py:1800\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   1797\u001b[0m     dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dim, (\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mSymInt)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dim) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1798\u001b[0m ):\n\u001b[1;32m   1799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1800\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1803\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1804\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\n\u001b[1;32m   1805\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m2\u001b[39m, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout\n\u001b[1;32m   1806\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the best scores, parameters, models, and training histories for each dataset\n",
    "best_scores = []  # Use a list of three elements to store the scores for each dataset\n",
    "best_params_list = []  # List of three elements to store the best hyperparameter configurations for each dataset\n",
    "best_models = []  # List of three elements to store the best models for each dataset\n",
    "best_histories = []  # List of three elements to store the training histories for each dataset\n",
    "\n",
    "\n",
    "# Determine the input size\n",
    "input_size = X_train_scaled.shape[1]\n",
    "output_size = 3\n",
    "\n",
    "# Define the range of hyperparameters for the grid search\n",
    "param_ranges_1 = {\n",
    "    \"learning_rate\": (0.007, 0.01, 0.001),  # Da 0.01 a 0.5 con step di 0.05\n",
    "    \"epochs\": (700, 700, 1),                   # Da 0 a 10 con step di 1\n",
    "    \"batch_size\": (128, 128, 1),             # Da 8 a 32 con step di 8\n",
    "    \"hidden_size\": (30, 80, 10),           # Da 32 a 128 con step di 32\n",
    "    \"hidden_layers\": (2, 3, 1),             # Da 1 a 3 con step di 1\n",
    "    \"momentum\": (0.2, 0.8, 0.1),          # Da 0.9 a 0.99 con step di 0.01\n",
    "    \"regularization\": (0.01, 0.01, 0.01),             # Da 0.0 a 0.1 con step di 0.05\n",
    "    \"alpha\": (0.01, 0.01, 0.01),             # Da 0.01 a 0.1 con step di 0.05\n",
    "    \"patience\": (30, 30, 1)            # Da 5 a 15 con step di 5\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters based on the specified ranges\n",
    "print(\"Generazione delle combinazioni di iperparametri...\")\n",
    "param_grid_monk1 = []\n",
    "param_grid_monk1 = generate_hyperparameter_combinations(param_ranges_1)\n",
    "\n",
    "\n",
    "print(\"--------------------------------------------------ML CUP--------------------------------------------------\")\n",
    "# Perform a greedy search over the hyperparameter grid\n",
    "best_scores, best_params_list, best_models, best_histories = greed_search(X_train_scaled, y_train_scaled, \n",
    "                                                                                      'tanh', 'SGD', True, \n",
    "                                                                                      input_size, output_size, param_grid_monk1)\n",
    "\n",
    "print(\"--------------------------------------------------Plots--------------------------------------------------\")\n",
    "# Iterate over the best histories, parameters, and scores to print and plot the results\n",
    "for i, (history, params, score) in enumerate(zip(best_histories, best_params_list, best_scores)):\n",
    "    print(f\"{params}\")\n",
    "    print(f\"Score: {score}\")\n",
    "    plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([15, 1, 3])) that is different to the input size (torch.Size([15, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([36, 1, 3])) that is different to the input size (torch.Size([36, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([16, 1, 3])) that is different to the input size (torch.Size([16, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([35, 1, 3])) that is different to the input size (torch.Size([35, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.02925568135097773\n",
      "Variance: 3.878880675303821e-06\n"
     ]
    }
   ],
   "source": [
    "# Determine the input and output sizes based on the scaled training data\n",
    "input_size = X_train_scaled.shape[1]\n",
    "output_size = y_train_scaled.shape[1]\n",
    "\n",
    "# Generate all possible combinations of hyperparameters based on the specified ranges\n",
    "param_grid_1 = [best_params_list[0]]\n",
    "\n",
    "scores, _ = double_k_fold_cross_validation(X_train_scaled, y_train_scaled, 'tanh', 'SGD', True, input_size, output_size, 5, 5, param_grid_1)\n",
    "\n",
    "\n",
    "\n",
    "variance = np.var(scores)\n",
    "mean = np.mean(scores)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Variance: {variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03877978086471558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML2/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([25, 1, 3])) that is different to the input size (torch.Size([25, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "_, test_mee, = evaluation(best_models[0], X_test_scaled, y_test_scaled, nn.MSELoss())\n",
    "print(test_mee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_best(data_loader, model, learning_rate, momentum, weight_decay, epochs, patience, optim_type = 'SGD', reg_flag = False, val_data=[], val_labels=[], test_data=[], test_labels=[]):\n",
    "    \"\"\"\n",
    "    Trains a neural network model with optional regularization and early stopping.\n",
    "\n",
    "    Args:\n",
    "        data_loader (DataLoader): DataLoader for training data.\n",
    "        model (nn.Module): The neural network model to train.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        momentum (float): Momentum value for the optimizer.\n",
    "        weight_decay (float): Weight decay (L2 regularization) value.\n",
    "        epochs (int): Number of training epochs.\n",
    "        patience (int): Patience for early stopping.\n",
    "        optim_type (str, optional): Optimizer type ('SGD' or 'Adam'). Default is 'SGD'.\n",
    "        reg_flag (bool, optional): Whether to apply regularization. Default is False.\n",
    "        val_data (list, optional): Validation data inputs. Default is an empty list.\n",
    "        val_labels (list, optional): Validation data labels. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the training history (loss and accuracy for both train and validation).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the loss function (Mean Squared Error Loss)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Set the optimizer based on the selected configuration\n",
    "    if reg_flag:\n",
    "        # If regularization is enabled, include weight decay in the optimizer\n",
    "        if optim_type == 'Adam':\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "        else:\n",
    "            optimizer = optim.SGD(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "    else:\n",
    "        # If regularization is not enabled, omit weight decay\n",
    "        if optim_type == 'Adam':\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True \n",
    "            )\n",
    "        else:\n",
    "            optimizer = optim.SGD(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                momentum=momentum, \n",
    "                nesterov=True \n",
    "            )\n",
    "\n",
    "    # Initialize a dictionary to track training and validation performance\n",
    "    history = {'train_loss': [], 'train_mee': [], 'val_loss': [], 'val_mee': [], 'test_loss': [], 'test_mee': []}\n",
    "    \n",
    "    # Create an early stopping object to prevent overfitting\n",
    "    early_stopping = EarlyStopping(patience, delta = 0.05, verbose=False)\n",
    "    \n",
    "    # Training loop for the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        total_mee = 0  # Initialize total Mean Euclidean Error (MEE) for the epoch\n",
    "        total_samples = 0  # Initialize total number of samples processed\n",
    "        last_loss = 0  # Variable to store the last loss for the epoch\n",
    "        \n",
    "        # Iterate over batches in the training data\n",
    "        for inputs, labels in data_loader:\n",
    "            optimizer.zero_grad()  # Reset gradients before the backward pass\n",
    "            outputs = model(inputs)  # Perform a forward pass through the model\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # Compute the loss between predictions and true labels\n",
    "            loss.backward()  # Perform backpropagation to compute gradients\n",
    "            optimizer.step()  # Update the model parameters using the optimizer\n",
    "\n",
    "            last_loss = loss.item()  # Store the current loss for reporting\n",
    "\n",
    "            # Calculate the Mean Euclidean Error (MEE) for the current batch\n",
    "            batch_mee = torch.norm(outputs - labels.unsqueeze(1), dim=1).mean().item()\n",
    "            total_mee += batch_mee  # Accumulate the MEE for the entire epoch\n",
    "            total_samples += labels.size(0)  # Count the number of samples processed\n",
    "\n",
    "        # Calculate the mean MEE for the entire epoch\n",
    "        mean_mee_epoch = total_mee / total_samples\n",
    "        history['train_loss'].append(last_loss)  # Record the training loss for the epoch\n",
    "        history['train_mee'].append(mean_mee_epoch)  # Record the mean MEE for the epoch\n",
    "\n",
    "        if test_data is not None and test_labels is not None and len(val_data) > 0 and len(val_labels) > 0:\n",
    "            result = evaluation(model, test_data, test_labels, criterion)  # Evaluate on validation set\n",
    "            history['test_loss'].append(result[0])  # Record the validation loss\n",
    "            history['test_mee'].append(result[1])  # Record the validation MEE      \n",
    "\n",
    "\n",
    "        # Validation for the current epoch (if validation data is provided)\n",
    "        if val_data is not None and val_labels is not None and len(val_data) > 0 and len(val_labels) > 0:\n",
    "            result = evaluation(model, val_data, val_labels, criterion)  # Evaluate on validation set\n",
    "            history['val_loss'].append(result[0])  # Record the validation loss\n",
    "            history['val_mee'].append(result[1])  # Record the validation MEE\n",
    "            early_stopping(result[0], model)  # Apply early stopping based on validation loss\n",
    "            if early_stopping.early_stop:\n",
    "                #print(\"Early stopping triggered!\")  # Print message when early stopping is triggered\n",
    "                break  # Stop training if early stopping criteria are met\n",
    "\n",
    "    return history  # Return the training history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_k_fold_cross_validation(data, labels, data_test, data_labels, activ_type = 'tanh', optim_type = 'SGD', reg_flag = False, input_size =12, output_size = 3, params=None):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation on the given dataset using a neural network model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - data (np.ndarray): Features of the dataset.\n",
    "    - labels (np.ndarray): Labels of the dataset.\n",
    "    - activ_type (str): Activation function type for hidden layers.\n",
    "    - optim_type (str): Optimizer type ('SGD' or 'Adam').\n",
    "    - reg_flag (bool): Flag to indicate whether to use L2 regularization.\n",
    "    - in_size (int): Number of input features.\n",
    "    - params (dict): Dictionary containing hyperparameters for the model.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    - avg_score (float): Average validation MEE across all folds.\n",
    "    - history (tf.keras.callbacks.History): Training history of the final model.\n",
    "    - model (tf.keras.Model): Trained Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Configuration of k-fold cross-validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Cross-validation loop\n",
    "    fold_no = 1\n",
    "    mee_per_fold = []\n",
    "    for train_index, val_index in kfold.split(data, labels):\n",
    "        \n",
    "        # Split the dataset into training and validation sets for the current fold\n",
    "        X_train, X_val = data[train_index], data[val_index]\n",
    "        y_train, y_val = labels[train_index], labels[val_index]\n",
    "        \n",
    "\n",
    "        dataset = CustomDataset(X_train, y_train)\n",
    "        data_loader = DataLoader(dataset, batch_size=int(params['batch_size']), shuffle=False)\n",
    "\n",
    "        # Create the neural network model\n",
    "        model = NN(input_size = input_size,\n",
    "                    hidden_size = params['hidden_size'],\n",
    "                    output_size = output_size,\n",
    "                    hidden_layers = params['hidden_layers'], \n",
    "                    alpha=params['alpha'],\n",
    "                    activ_type = activ_type)\n",
    "        \n",
    "        \n",
    "        # Train the model and obtain the histor\n",
    "        history = fit_best(data_loader=data_loader, model=model, learning_rate=params['learning_rate'], \n",
    "                        weight_decay=params['regularization'], momentum=params['momentum'],\n",
    "                        epochs=params['epochs'], patience = params['patience'], optim_type = optim_type, reg_flag = reg_flag, val_data=X_val, val_labels=y_val, \n",
    "                        test_data = data_test, test_labels = data_labels)\n",
    "        \n",
    "\n",
    "        # Get the best score (minimum validation MEE)\n",
    "        score = min(history['val_mee'])\n",
    "        mee_per_fold.append(score)\n",
    "        fold_no += 1\n",
    "\n",
    "    # Calculate the average score across all folds\n",
    "    avg_score = np.mean(mee_per_fold)\n",
    "\n",
    "    # Split the dataset into training and validation sets for the final training\n",
    "    X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create the neural network model for the final training\n",
    "    dataset = CustomDataset(X_train, y_train)\n",
    "    data_loader = DataLoader(dataset, batch_size=int(params['batch_size']), shuffle=False)\n",
    "\n",
    "    model = NN(input_size = input_size, hidden_size = params['hidden_size'], output_size = output_size,\n",
    "               hidden_layers = params['hidden_layers'], alpha=params['alpha'], activ_type = activ_type)\n",
    "        \n",
    "    history = fit_best(data_loader=data_loader, model=model, learning_rate=params['learning_rate'], \n",
    "                      weight_decay=params['regularization'], momentum=params['momentum'],\n",
    "                      epochs=params['epochs'], patience = params['patience'], \n",
    "                      optim_type = optim_type, reg_flag = reg_flag, val_data=X_val, \n",
    "                      val_labels=y_val, test_data = data_test, test_labels = data_labels)\n",
    "\n",
    "    # Return the average score, training history, and the final model\n",
    "    return avg_score, history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.009000000000000001, 'epochs': 700, 'batch_size': 128, 'hidden_size': 70, 'hidden_layers': 3, 'momentum': 0.8000000000000003, 'regularization': 0.01, 'alpha': 0.01, 'patience': 30}\n",
      "Score: 0.0292384826173686\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_size = X_train_scaled.shape[1]\n",
    "output_size = y_train_scaled.shape[1]\n",
    "\n",
    "# Perform k-fold cross-validation with the current set of hyperparameters\n",
    "score, history, model_cup = best_k_fold_cross_validation(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, 'tanh', 'SGD', True, input_size = input_size, output_size=output_size, params=best_params_list[0])\n",
    "\n",
    "print(f\"{params}\")\n",
    "print(f\"Score: {score}\")\n",
    "plot_best_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for blind test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../team_rocket_pred.csv' generato con successo!\n"
     ]
    }
   ],
   "source": [
    "# Converti il blind test in un dataset PyTorch\n",
    "# Dati per le prime 4 righe del file\n",
    "names = \"Giuseppe Gabriele Russo, Mario Mogavero\"  # Sostituisci con i tuoi nomi\n",
    "team = \"Team Rocket\"    # Sostituisci con il tuo team nickname\n",
    "dataset_name = \"ML-CUP24 v1\"\n",
    "date = datetime.datetime.now().strftime(\"%d %b %Y\")  # Data attuale formattata\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation (saves memory and computations)\n",
    "        inputs = torch.tensor(X_blind_test_scaled, dtype=torch.float32)  # Convert input data to tensor\n",
    "        y_blind_test_scaled = model_cup(inputs)  # Perform a forward pass through the model\n",
    "# Genera le predizioni\n",
    "\n",
    "#y_blind_test_scaled = y_blind_test_scaled.numpy()\n",
    "\n",
    "# Denormalizza le predizioni\n",
    "y_blind_test = output_scaler.inverse_transform(y_blind_test_scaled)\n",
    "\n",
    "# Salva i risultati in un file CSV\n",
    "ids = range(1, len(X_blind_test_scaled) + 1)\n",
    "output_filename = \"../team_rocket_pred.csv\"\n",
    "with open(output_filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Scrivi le prime 4 righe come commenti\n",
    "    writer.writerow([f\"# {names}\"])\n",
    "    writer.writerow([f\"# {team}\"])\n",
    "    writer.writerow([f\"# {dataset_name}\"])\n",
    "    writer.writerow([f\"# {date}\"])\n",
    "\n",
    "    # Scrivi i risultati\n",
    "    for i, result in zip(ids, y_blind_test):\n",
    "        writer.writerow([i, result[0], result[1], result[2]])  # Se ci sono più colonne, aggiungile qui\n",
    "\n",
    "print(f\"File '{output_filename}' generato con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
