{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hyperparameter_combinations(param_ranges):\n",
    "    '''\n",
    "    Parameters:\n",
    "    param_ranges (dict): Dictionary with hyperparameter names as keys.\n",
    "                         Each value is a tuple (start, stop, step) indicating the range and step size for the hyperparameter.\n",
    "    Returns:\n",
    "    list: List of dictionaries with all possible combinations of hyperparameters.\n",
    "    '''\n",
    "    param_values = {\n",
    "        key: np.arange(start, stop + step, step)\n",
    "        for key, (start, stop, step) in param_ranges.items()\n",
    "    }\n",
    "    \n",
    "    param_combinations = list(itertools.product(*param_values.values()))\n",
    "    return [\n",
    "        dict(zip(param_values.keys(), combination))\n",
    "        for combination in param_combinations\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
    "\n",
    "# Load training and test files for each dataset from the specified path\n",
    "monk1_train = pd.read_csv('../Datasets/Monks/monks-1.train', sep='\\s+', header=None)\n",
    "monk1_test = pd.read_csv('../Datasets/Monks/monks-1.test', sep='\\s+', header=None)\n",
    "\n",
    "monk2_train = pd.read_csv('../Datasets/Monks/monks-2.train', sep='\\s+', header=None)\n",
    "monk2_test = pd.read_csv('../Datasets/Monks/monks-2.test', sep='\\s+', header=None)\n",
    "\n",
    "monk3_train = pd.read_csv('../Datasets/Monks/monks-3.train', sep='\\s+', header=None)\n",
    "monk3_test = pd.read_csv('../Datasets/Monks/monks-3.test', sep='\\s+', header=None)\n",
    "\n",
    "# List to store the transformed datasets\n",
    "monks_train = []\n",
    "monks_test = []\n",
    "\n",
    "# Dataset monk1\n",
    "X1_train = monk1_train.iloc[:, 1:7].values  # Features\n",
    "y1_train = monk1_train.iloc[:, 0].values    # Labels\n",
    "\n",
    "X1_test = monk1_test.iloc[:, 1:7].values\n",
    "y1_test = monk1_test.iloc[:, 0].values\n",
    "\n",
    "# Apply encoder to monk1\n",
    "X1_train_encoded = encoder.fit_transform(X1_train)  # Fit and transform on training data\n",
    "X1_test_encoded = encoder.transform(X1_test)        # Only transform on test data\n",
    "\n",
    "monks_train.append((X1_train_encoded, y1_train))\n",
    "monks_test.append((X1_test_encoded, y1_test))\n",
    "\n",
    "# Dataset monk2\n",
    "X2_train = monk2_train.iloc[:, 1:7].values\n",
    "y2_train = monk2_train.iloc[:, 0].values\n",
    "\n",
    "X2_test = monk2_test.iloc[:, 1:7].values\n",
    "y2_test = monk2_test.iloc[:, 0].values\n",
    "\n",
    "# Apply encoder to monk2\n",
    "X2_train_encoded = encoder.fit_transform(X2_train)\n",
    "X2_test_encoded = encoder.transform(X2_test)\n",
    "\n",
    "monks_train.append((X2_train_encoded, y2_train))\n",
    "monks_test.append((X2_test_encoded, y2_test))\n",
    "\n",
    "# Dataset monk3\n",
    "X3_train = monk3_train.iloc[:, 1:7].values\n",
    "y3_train = monk3_train.iloc[:, 0].values\n",
    "\n",
    "X3_test = monk3_test.iloc[:, 1:7].values\n",
    "y3_test = monk3_test.iloc[:, 0].values\n",
    "\n",
    "# Apply encoder to monk3\n",
    "X3_train_encoded = encoder.fit_transform(X3_train)\n",
    "X3_test_encoded = encoder.transform(X3_test)\n",
    "\n",
    "monks_train.append((X3_train_encoded, y3_train))\n",
    "monks_test.append((X3_test_encoded, y3_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_KNN(K=100):\n",
    "    '''\n",
    "    Create an K-NN model with the parameter K.\n",
    "    param K: Regularization parameter.\n",
    "    return: K-NN model.\n",
    "    '''\n",
    "    return KNeighborsClassifier(n_neighbors=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data, labels, params=None):\n",
    "    '''\n",
    "    Perform k-fold cross-validation for SVM.\n",
    "    param data: Feature data.\n",
    "    param labels: Target labels.\n",
    "    param type: Kernel type for SVM.\n",
    "    param params: Dictionary of hyperparameters.\n",
    "    return: Average score and trained model.\n",
    "    '''\n",
    "    # 3. Configure k-fold cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    print(kfold)\n",
    "    print(data)\n",
    "    print(labels)\n",
    "    # 4. Cross-validation loop\n",
    "    fold_no = 1\n",
    "    accuracy_per_fold = []\n",
    "    for train_index, val_index in kfold.split(data, labels):\n",
    "        \n",
    "        # Split the dataset\n",
    "        X_train, X_val = data[train_index], data[val_index]\n",
    "        y_train, y_val = labels[train_index], labels[val_index]\n",
    "\n",
    "        # Create the SVM model\n",
    "        model = create_KNN(K=params['K'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on validation set\n",
    "        pred = model.predict(X_val)\n",
    "        \n",
    "        # Get the accuracy score\n",
    "        score = accuracy_score(pred, y_val)\n",
    "        accuracy_per_fold.append(score)    \n",
    "        fold_no += 1\n",
    "\n",
    "    # Calculate the average score\n",
    "    avg_score = np.mean(accuracy_per_fold)\n",
    "\n",
    "    # Split the dataset for final training\n",
    "    _, X_val, _, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the SVM model\n",
    "    model = create_KNN(K=params['K'])\n",
    "\n",
    "    # Train the model on the entire dataset\n",
    "    model.fit(data, labels)\n",
    "\n",
    "    return avg_score, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greed search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greed_search(data, labels, param_grid=None):\n",
    "    '''\n",
    "    Perform greedy search for hyperparameter tuning.\n",
    "    param data: Feature data.\n",
    "    param labels: Target labels.\n",
    "    param type: Kernel type for SVM.\n",
    "    param param_grid: List of hyperparameter combinations.\n",
    "    return: Best scores, best parameter configurations, and best models.\n",
    "    '''\n",
    "    best_scores = []  # List to store the scores\n",
    "    best_params_list = []  # List to store the parameter configurations\n",
    "    best_models = []  # List to store the models\n",
    "    \n",
    "    for params in param_grid:\n",
    "        # Perform k-fold cross-validation\n",
    "        score, model = k_fold_cross_validation(data, labels, params=params)\n",
    "\n",
    "        # Add the results to the list\n",
    "        best_scores.append(score)\n",
    "        best_params_list.append(params)\n",
    "        best_models.append(model)\n",
    "\n",
    "        # Sort the list of scores and keep only the top 5\n",
    "        sorted_indices = np.argsort(best_scores)[::-1]  # Sort the scores in descending order\n",
    "        best_scores = [best_scores[i] for i in sorted_indices][:5]  # Keep the top 5 scores\n",
    "        best_params_list = [best_params_list[i] for i in sorted_indices][:5]\n",
    "        best_models = [best_models[i] for i in sorted_indices][:5]\n",
    "\n",
    "    return best_scores, best_params_list, best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(data, labels):\n",
    "    '''\n",
    "    Perform hyperparameter selection for SVM models.\n",
    "    param data: Feature data.\n",
    "    param labels: Target labels.\n",
    "    return: Best scores, best parameter configurations, and best models.\n",
    "    '''\n",
    "\n",
    "    # Define the range of hyperparameters\n",
    "    param_ranges = {\n",
    "        \"K\": (1, 1000, 10),  # From 1 to 1000 with step of 10\n",
    "    }\n",
    "\n",
    "    print(\"Generating hyperparameter combinations...\")\n",
    "    param_grid = generate_hyperparameter_combinations(param_ranges)\n",
    "\n",
    "    best_scores = []  # List to store the scores\n",
    "    best_params_list = []  # List to store the parameter configurations\n",
    "    best_models = []  # List to store the models\n",
    "\n",
    "    actual_scores, actual_params_list, actual_models = greed_search(data, labels, param_grid)\n",
    "\n",
    "    # Extend the lists with the results from the current kernel type\n",
    "    best_scores.extend(actual_scores)\n",
    "    best_params_list.extend(actual_params_list)\n",
    "    best_models.extend(actual_models)\n",
    "\n",
    "    # Sort the scores in descending order and keep only the top 5\n",
    "    sorted_indices = np.argsort(best_scores)[::-1]\n",
    "    best_scores = [best_scores[i] for i in sorted_indices][:5]\n",
    "    best_params_list = [best_params_list[i] for i in sorted_indices][:5]\n",
    "    best_models = [best_models[i] for i in sorted_indices][:5]\n",
    "\n",
    "    # Print the best scores, kernel types, and parameter configurations\n",
    "    for i in range(len(best_scores)):\n",
    "        print(f\"Score: {best_scores[i]}, parameters: {best_params_list[i]}\")\n",
    "\n",
    "    return best_scores, best_params_list, best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------MONK1-----------------\n",
      "Generating hyperparameter combinations...\n",
      "StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 1.]]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis script performs model selection for three different MONK datasets using the `selection` function.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Run this script to perform model selection on the MONK datasets and obtain the best models for each dataset.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------MONK1-----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m _, _, best_models_monk_1 \u001b[38;5;241m=\u001b[39m selection(monks_train[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], monks_train[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------MONK2-----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m _, _, best_models_monk_2 \u001b[38;5;241m=\u001b[39m selection(monks_train[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], monks_train[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m, in \u001b[0;36mselection\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m     18\u001b[0m best_params_list \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List to store the parameter configurations\u001b[39;00m\n\u001b[1;32m     19\u001b[0m best_models \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List to store the models\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m actual_scores, actual_params_list, actual_models \u001b[38;5;241m=\u001b[39m greed_search(data, labels, param_grid)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Extend the lists with the results from the current kernel type\u001b[39;00m\n\u001b[1;32m     24\u001b[0m best_scores\u001b[38;5;241m.\u001b[39mextend(actual_scores)\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mgreed_search\u001b[0;34m(data, labels, param_grid)\u001b[0m\n\u001b[1;32m     12\u001b[0m best_models \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List to store the models\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Perform k-fold cross-validation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     score, model \u001b[38;5;241m=\u001b[39m k_fold_cross_validation(data, labels, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Add the results to the list\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     best_scores\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36mk_fold_cross_validation\u001b[0;34m(data, labels, params)\u001b[0m\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get the accuracy score\u001b[39;00m\n\u001b[1;32m     34\u001b[0m score \u001b[38;5;241m=\u001b[39m accuracy_score(pred, y_val)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:249\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    247\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[1;32m    248\u001b[0m     ):\n\u001b[0;32m--> 249\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    252\u001b[0m                 [\n\u001b[1;32m    253\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[idx][np\u001b[38;5;241m.\u001b[39margmax(probas, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    257\u001b[0m             )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:350\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    351\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py:822\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    815\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    818\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    819\u001b[0m     )\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 822\u001b[0m     results \u001b[38;5;241m=\u001b[39m ArgKmin\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    823\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    824\u001b[0m         Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[1;32m    825\u001b[0m         k\u001b[38;5;241m=\u001b[39mn_neighbors,\n\u001b[1;32m    826\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_,\n\u001b[1;32m    827\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_,\n\u001b[1;32m    828\u001b[0m         strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    829\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    830\u001b[0m     )\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    834\u001b[0m ):\n\u001b[1;32m    835\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    836\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    837\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:258\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin64\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    259\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    260\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[1;32m    261\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    262\u001b[0m         metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m    263\u001b[0m         chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[1;32m    264\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39mmetric_kwargs,\n\u001b[1;32m    265\u001b[0m         strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    266\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    267\u001b[0m     )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    271\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    272\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    279\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:90\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py:72\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[0;34m(limits, user_api)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m threadpoolctl\u001b[38;5;241m.\u001b[39mthreadpool_limits(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[0;34m(self, limits, user_api)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(limits, user_api)\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_threadpool_limits()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m modules \u001b[38;5;241m=\u001b[39m _ThreadpoolInfo(prefixes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes,\n\u001b[1;32m    269\u001b[0m                           user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[0;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_modules()\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:371\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loop through loaded libraries and store supported ones\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dyld()\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_enum_process_module_ex()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:428\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_dyld\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m filepath \u001b[38;5;241m=\u001b[39m filepath\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_module_from_path(filepath)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[1;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[0;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class(filepath, prefix, user_api, internal_api)\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_version()\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[0;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script performs model selection for three different MONK datasets using the `selection` function.\n",
    "\n",
    "The script prints headers for each MONK dataset and then calls the `selection` function with the training data for each dataset.\n",
    "The results of the selection process are stored in variables `best_models_monk_1`, `best_models_monk_2`, and `best_models_monk_3`.\n",
    "\n",
    "Variables:\n",
    "    monks_train (list): A list containing training data for the three MONK datasets.\n",
    "    best_models_monk_1 (object): The best models selected for the MONK1 dataset.\n",
    "    best_models_monk_2 (object): The best models selected for the MONK2 dataset.\n",
    "    best_models_monk_3 (object): The best models selected for the MONK3 dataset.\n",
    "\n",
    "Functions:\n",
    "    selection(X, y): A function that performs model selection given features `X` and labels `y`.\n",
    "\n",
    "Usage:\n",
    "    Run this script to perform model selection on the MONK datasets and obtain the best models for each dataset.\n",
    "\"\"\"\n",
    "\n",
    "print(\"-----------------MONK1-----------------\")\n",
    "_, _, best_models_monk_1 = selection(monks_train[0][0], monks_train[0][1])\n",
    "print(\"-----------------MONK2-----------------\")\n",
    "_, _, best_models_monk_2 = selection(monks_train[1][0], monks_train[1][1])\n",
    "print(\"-----------------MONK3-----------------\")\n",
    "_, _, best_models_monk_3 = selection(monks_train[2][0], monks_train[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_models_monk_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5. Model evaluation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y1_pred \u001b[38;5;241m=\u001b[39m best_models_monk_1[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(X1_test_encoded)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 6. Report the results\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y1_test, y1_pred))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_models_monk_1' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Model evaluation\n",
    "y1_pred = best_models_monk_1[0].predict(X1_test_encoded)\n",
    "\n",
    "# 6. Report the results\n",
    "print(\"Accuracy:\", accuracy_score(y1_test, y1_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7731481481481481\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       290\n",
      "           1       0.62      0.77      0.69       142\n",
      "\n",
      "    accuracy                           0.77       432\n",
      "   macro avg       0.75      0.77      0.76       432\n",
      "weighted avg       0.79      0.77      0.78       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Model evaluation\n",
    "y2_pred = best_models_monk_2[0].predict(X2_test_encoded)\n",
    "\n",
    "# 6. Report the results\n",
    "print(\"Accuracy:\", accuracy_score(y2_test, y2_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9722222222222222\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       204\n",
      "           1       1.00      0.95      0.97       228\n",
      "\n",
      "    accuracy                           0.97       432\n",
      "   macro avg       0.97      0.97      0.97       432\n",
      "weighted avg       0.97      0.97      0.97       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set for MONK3\n",
    "y3_pred = best_models_monk_3[0].predict(X3_test_encoded)\n",
    "\n",
    "# Report the results\n",
    "print(\"Accuracy:\", accuracy_score(y3_test, y3_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y3_test, y3_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
